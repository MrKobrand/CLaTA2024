{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nhuY1meSq3-C"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ],
      "metadata": {
        "id": "tNHBwdXiGMN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1a35b5-b9b6-4ad3-b90a-ad0a58948fb5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaG8-OTZq3-E"
      },
      "source": [
        "\n",
        "# Обработка естественного языка с нуля: перевод с помощью сети последовательностей и внимания\n",
        "**Автор**: [Sean Robertson](https://github.com/spro)\n",
        "\n",
        "В этом проекте будет происходить обучение нейронной сети переводу c русского на английский.\n",
        "\n",
        "```sh\n",
        "[KEY: > input, = target, < output]\n",
        "\n",
        "> вы мне не поверите\n",
        "= you re not going to believe me\n",
        "< you re not going to believe me\n",
        "\n",
        "> она всеми любима\n",
        "= she is loved by everybody\n",
        "< she is loved by all this family\n",
        "\n",
        "> мы оба из австралии\n",
        "= we re both from australia\n",
        "< we re both from australia\n",
        "\n",
        "> я герои тома\n",
        "= i m tom s hero\n",
        "< tom is tom s hero\n",
        "```\n",
        "... с разной степенью успеха.\n",
        "\n",
        "Это стало возможным благодаря простой, но мощной идее сети последовательностей, в которой две рекуррентные нейронные сети работают вместе для преобразования одной последовательности в другую. Сеть кодировщика преобразует входную последовательность в вектор, а сеть декодера разворачивает этот вектор в новую последовательность.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
        "\n",
        "Чтобы улучшить эту модель, мы будем использовать [механизм](https://arxiv.org/abs/1409.0473), который позволяет декодеру научиться фокусироваться на определенном диапазоне входной последовательности.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OjrETR0Vq3-G"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td_U1XnGq3-H"
      },
      "source": [
        "## Загрузка файлов данных\n",
        "\n",
        "Данные для этого проекта представляют собой набор из многих тысяч пар перевода с английского на русский язык.\n",
        "\n",
        "Пары с английского на русский слишком велики, чтобы их можно было включить в репозиторий, поэтому, поэтому скачайте `data/rus.txt` перед продолжением. Файл представляет собой список пар перевода, разделенный табуляцией:\n",
        "\n",
        "```sh\n",
        "Go now.\tА теперь уходи.\n",
        "```\n",
        "<div class=\"alert alert-info\"><h4>Примечание</h4><p>Скачайте данные с\n",
        "   <a href=\"https://www.manythings.org/anki/rus-eng.zip\">сайта</a>\n",
        "   и извлеките содержимое в текущую директорию.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vDjFDZoq3-I"
      },
      "source": [
        "Подобно кодировке символов, используемой в учебных пособиях по RNN на уровне символов, мы будем представлять каждое слово в языке как вектор с единицей измерения или гигантский вектор нулей, за исключением одного (в индексе слова). По сравнению с десятками символов, которые могут существовать в языке, слов гораздо больше, поэтому вектор кодирования намного больше. Однако мы немного схитрим и обрежем данные, чтобы использовать только несколько тысяч слов на каждый язык.\n",
        "\n",
        "![word encoding](https://pytorch.org/tutorials/_images/word-encoding.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sA0f9-mq3-I"
      },
      "source": [
        "Нам понадобится уникальный индекс для каждого слова, чтобы позже использовать его в качестве входных данных и целей сетей. Чтобы отслеживать все это, мы будем использовать вспомогательный класс под названием Lang, который имеет словари слово → индекс (`word2index`) и индекс → слово (`index2word`), а также количество каждого слова `word2count`, которое позже будет использоваться для замены редких слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NsrM5UfEq3-J"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNzak1Y9q3-K"
      },
      "source": [
        "Все файлы представлены в формате Unicode, поэтому для упрощения мы преобразуем символы Unicode в ASCII, сделаем все строчными и урежем большую часть знаков препинания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Vk-jPEPBq3-L"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^а-яА-Яa-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9GwXG82q3-L"
      },
      "source": [
        "Чтобы прочитать файл данных, мы разделим файл на строки, а затем разобьем строки на пары. Все файлы — английский → другой язык, поэтому, если мы хотим перевести с другого языка → английский, я добавил флаг `reverse`, чтобы поменять местами пары."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Q_HGnLkOq3-M"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gDL1aXCq3-M"
      },
      "source": [
        "Поскольку примеров предложений *много* и мы хотим что-то быстро обучить, мы сократим набор данных до относительно коротких и простых предложений. Здесь максимальная длина составляет 10 слов (включая конечные знаки препинания), и мы фильтруем предложения, которые переводятся в форму «Я есть» или «Он есть» и т. д. (с учетом замененных ранее апострофов)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TDxfhZBPq3-M"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUcsHReVq3-M"
      },
      "source": [
        "Полный процесс подготовки данных:\n",
        "\n",
        "- Прочитать текстовый файл и разбить его на строки, разбивать строки на пары;\n",
        "- Нормализовать текст, отфильтровать по длине и содержанию;\n",
        "- Составить списки слов из предложений в парах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JWk1wZWAq3-M",
        "outputId": "30c34e76-a225-47af-94b5-f1e40103a9ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 487600 sentence pairs\n",
            "Trimmed to 30189 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 10444\n",
            "eng 4333\n",
            "['он на два года старше меня', 'he s two years older than me']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA6Tx-SGq3-O"
      },
      "source": [
        "## Модель Seq2Seq\n",
        "\n",
        "Рекуррентная нейронная сеть, или RNN, — это сеть, которая работает с последовательностью и использует свои собственные выходные данные в качестве входных данных для последующих шагов.\n",
        "\n",
        "[Сеть последовательного преобразования](https://arxiv.org/abs/1409.3215), или сеть seq2seq, или [сеть кодировщика-декодера](https://arxiv.org/pdf/1406.1078v3.pdf), — это модель, состоящая из двух RNN, называемых кодером и декодером. Кодер считывает входную последовательность и выводит один вектор, а декодер считывает этот вектор для создания выходной последовательности.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
        "\n",
        "В отличие от прогнозирования последовательности с помощью одной RNN, где каждый вход соответствует выходу, модель seq2seq освобождает нас от длины и порядка последовательности, что делает ее идеальной для перевода между двумя языками.\n",
        "\n",
        "С помощью модели seq2seq кодер создает один вектор, который в идеальном случае кодирует «значение» входной последовательности в один вектор — одну точку в некотором N-мерном пространстве предложений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0SYWzCYq3-O"
      },
      "source": [
        "### Кодер\n",
        "\n",
        "Кодер сети seq2seq — это RNN, которая выводит некоторое значение для каждого слова из входного предложения. Для каждого входного слова кодер выводит вектор и скрытое состояние и использует скрытое состояние для следующего входного слова.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OewHDOl0q3-O"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzxVES7hq3-P"
      },
      "source": [
        "### Декодер\n",
        "\n",
        "Декодер — это еще одна RNN, которая принимает выходные векторы кодера и выводит последовательность слов для создания перевода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOz27_A6q3-P"
      },
      "source": [
        "#### Простой декодер\n",
        "\n",
        "В простейшем декодере seq2seq мы используем только последний вывод кодера. Этот последний результат иногда называют *вектором контекста*, поскольку он кодирует контекст всей последовательности. Этот вектор контекста используется как начальное скрытое состояние декодера.\n",
        "\n",
        "На каждом этапе декодирования декодеру предоставляется входной токен и скрытое состояние. Начальным входным токеном является токен начала строки `<SOS>`, а первым скрытым состоянием является вектор контекста (последнее скрытое состояние кодировщика).\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/decoder-network.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "K4kjcABIq3-P"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7w5GROdq3-P"
      },
      "source": [
        "Я призываю вас тренироваться и наблюдать за результатами этой модели, но для экономии места мы сразу перейдем к золоту и введем механизм внимания.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4zJg1lUq3-P"
      },
      "source": [
        "#### Декодер внимания\n",
        "\n",
        "Если между кодером и декодером передается только вектор контекста, этот единственный вектор несет бремя кодирования всего предложения.\n",
        "\n",
        "Внимание позволяет сети декодера «сосредотачиваться» на различных частях выходных данных кодера на каждом этапе собственных выходных данных декодера. Сначала мы вычисляем набор *весов внимания*. Они будут умножены на выходные векторы кодера для создания взвешенной комбинации. Результат (называемый в коде `attn_applied`) должен содержать информацию об этой конкретной части входной последовательности и, таким образом, помогать декодеру выбирать правильные выходные слова.\n",
        "\n",
        "![seq2seq](https://i.imgur.com/1152PYf.png)\n",
        "\n",
        "Вычисление весов внимания выполняется с помощью другого слоя прямой связи «attn», используя в качестве входных данных входные данные декодера и скрытое состояние. Поскольку в обучающих данных присутствуют предложения всех размеров, для фактического создания и обучения этого слоя нам нужно выбрать максимальную длину предложения (входная длина для выходных данных кодера), к которой оно может применяться. В предложениях максимальной длины будут использоваться все веса внимания, в то время как в более коротких предложениях будут использоваться только первые несколько.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/attention-decoder-network.png)\n",
        "\n",
        "Внимание Багданау, также известное как аддитивное внимание, является широко используемым механизмом внимания в моделях последовательного перевода, особенно в задачах нейронного машинного перевода. Он был введен Богданау и др. в своей статье под названием «Нейронный машинный перевод путем совместного обучения выравниванию и переводу» (https://arxiv.org/pdf/1409.0473.pdf). Этот механизм внимания использует изученную модель выравнивания для вычисления оценок внимания между скрытыми состояниями кодера и декодера. Он использует нейронную сеть прямого распространения для расчета показателей выравнивания.\n",
        "\n",
        "Однако существуют альтернативные механизмы внимания, такие как внимание Луонга, которое вычисляет оценки внимания, взяв скалярное произведение между скрытым состоянием декодера и скрытыми состояниями кодера. Здесь не используется нелинейное преобразование, используемое во внимании Богданау.\n",
        "\n",
        "В этом проекте мы будем использовать внимание Богданау. Однако было бы ценным упражнением изучить возможность изменения механизма внимания для использования внимания Луонга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UQXykD3wq3-P"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfxcgpwCq3-Q"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Примечание</h4><p>Существуют и другие формы внимания, которые позволяют обойти ограничение длины, используя подход относительного положения. Прочтите о «локальном внимании» в разделе <a href=\"https://arxiv.org/abs/1508.04025\">Эффективные подходы к нейронному машинному переводу, основанному на внимании</a>.</p></div>\n",
        "\n",
        "## Обучение\n",
        "\n",
        "### Подготовка данных обучения\n",
        "\n",
        "Для обучения для каждой пары нам понадобится входной тензор (индексы слов во входном предложении) и целевой тензор (индексы слов в целевом предложении). При создании этих векторов мы добавим токен EOS к обеим последовательностям.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9qWcreA-q3-Q"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fpRAPeWq3-Q"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "Для обучения мы пропускаем входное предложение через кодировщик и отслеживаем каждый вывод и последнее скрытое состояние. Затем декодер получает токен `<SOS>` в качестве первого входного сигнала и последнее скрытое состояние кодера в качестве его первого скрытого состояния.\n",
        "\n",
        "«Принуждение учителя» — это концепция использования реальных целевых выходных данных в качестве каждого следующего входного сигнала вместо использования предположения декодера в качестве следующего входного сигнала. Использование принуждения учителя приводит к более быстрой сходимости, но [когда обученная сеть используется, она может проявлять нестабильность](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "Вы можете наблюдать выходные данные сетей, навязанных учителем, которые читают с последовательной грамматикой, но отклоняются далеко от правильного перевода - интуитивно они научились представлять выходную грамматику и могут «уловить» смысл, как только учитель скажет им первые несколько слов, но он вообще не научился должным образом создавать предложение на основе перевода.\n",
        "\n",
        "Благодаря свободе, которую дает нам автоградация PyTorch, мы можем случайным образом выбирать, использовать принуждение учителя или нет с помощью простого оператора if. Включите `teacher_forcing_ratio`, чтобы использовать его больше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tMTEbp6pq3-Q"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WK5zqnXq3-R"
      },
      "source": [
        "Это вспомогательная функция для печати прошедшего времени и расчетного оставшегося времени с учетом текущего времени и процента прогресса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Bzr8qWktq3-R"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrVoMJGCq3-R"
      },
      "source": [
        "Весь процесс обучения выглядит так:\n",
        "\n",
        "- Запустить таймер;\n",
        "- Проинициализировать оптимизаторы и критерии;\n",
        "- Создать набор обучающих пар;\n",
        "- Запустить пустой массив потерь для построения графика.\n",
        "\n",
        "Затем мы много раз вызываем `train` и время от времени печатаем прогресс (%\n",
        "примеров, время на данный момент, расчетное время) и средние потери."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "uDADYk0Wq3-R"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z29c0CsYq3-R"
      },
      "source": [
        "### Отображение результатов\n",
        "\n",
        "Построение графика выполняется с помощью matplotlib с использованием массива значений потерь `plot_losses`, сохраненного во время обучения.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "cTdCGzVTq3-R"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO54flfHq3-S"
      },
      "source": [
        "## Оценка\n",
        "\n",
        "Оценка в основном аналогична обучению, но здесь нет целей, поэтому мы просто передаем прогнозы декодера самому себе для каждого шага. Каждый раз, когда он предсказывает слово, мы добавляем его в выходную строку, и если он предсказывает токен EOS, мы на этом останавливаемся. Мы также сохраняем выходные данные внимания декодера для последующего отображения.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LSfoW5-Hq3-S"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdtbUL5jq3-S"
      },
      "source": [
        "Мы можем оценить случайные предложения из обучающего набора и распечатать входные, целевые и выходные данные, чтобы сделать некоторые субъективные оценки качества:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-dNDS_Gdq3-S"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHPa7Hpgq3-S"
      },
      "source": [
        "## Обучение и оценка\n",
        "\n",
        "Имея все эти вспомогательные функции (это выглядит как дополнительная работа, но упрощает проведение нескольких экспериментов), мы фактически можем инициализировать сеть и начать обучение.\n",
        "\n",
        "Помните, что входные предложения были тщательно отфильтрованы. Для этого небольшого набора данных мы можем использовать относительно небольшие сети из 256 скрытых узлов и одного уровня GRU.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "  <h4>Примечание</h4>\n",
        "  <p>Если вы запустите этот блокнот, вы сможете тренироваться, прерывать работу ядра, оценивать и продолжать позже. Закомментируйте строки, в которых инициализируются кодировщик и декодер, и снова запустите <code>trainIters</code>.\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "lBn-egXiq3-Y",
        "outputId": "477536c5-00c0-42ad-a9e3-1a6e3573758a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 487600 sentence pairs\n",
            "Trimmed to 30189 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 10444\n",
            "eng 4333\n",
            "10m 8s (- 152m 4s) (5 6%) 1.2638\n",
            "20m 9s (- 141m 8s) (10 12%) 0.5043\n",
            "30m 0s (- 130m 2s) (15 18%) 0.2847\n",
            "39m 46s (- 119m 18s) (20 25%) 0.1883\n",
            "49m 39s (- 109m 14s) (25 31%) 0.1408\n",
            "59m 32s (- 99m 14s) (30 37%) 0.1153\n",
            "69m 21s (- 89m 10s) (35 43%) 0.0991\n",
            "79m 12s (- 79m 12s) (40 50%) 0.0882\n",
            "89m 26s (- 69m 34s) (45 56%) 0.0811\n",
            "99m 25s (- 59m 39s) (50 62%) 0.0754\n",
            "109m 14s (- 49m 39s) (55 68%) 0.0713\n",
            "119m 9s (- 39m 43s) (60 75%) 0.0682\n",
            "129m 10s (- 29m 48s) (65 81%) 0.0659\n",
            "139m 9s (- 19m 52s) (70 87%) 0.0634\n",
            "148m 57s (- 9m 55s) (75 93%) 0.0614\n",
            "158m 36s (- 0m 0s) (80 100%) 0.0602\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pNs-tlBq3-Y"
      },
      "source": [
        "Установим выпадающие слои в режим `eval`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "2GBojGzQq3-Y",
        "outputId": "2c2c8a32-3f12-4822-d43a-720bc11d3553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> вы мне не поверите\n",
            "= you re not going to believe me\n",
            "< you re not going to believe me <EOS>\n",
            "\n",
            "> она всеми любима\n",
            "= she is loved by everybody\n",
            "< she is loved by all this family <EOS>\n",
            "\n",
            "> мы оба из австралии\n",
            "= we re both from australia\n",
            "< we re both from australia <EOS>\n",
            "\n",
            "> я герои тома\n",
            "= i m tom s hero\n",
            "< tom is tom s hero <EOS>\n",
            "\n",
            "> я ничему не учусь\n",
            "= i m not learning anything\n",
            "< i m not learning anything <EOS>\n",
            "\n",
            "> вы сильнее нас\n",
            "= you re stronger than us\n",
            "< you re stronger than us <EOS>\n",
            "\n",
            "> сеичас у меня нет недомогания\n",
            "= i m not feeling bad at the moment\n",
            "< i m not feeling now <EOS>\n",
            "\n",
            "> я оптимист\n",
            "= i m an optimist\n",
            "< i m optimistic <EOS>\n",
            "\n",
            "> я пишу статью для школьнои газеты\n",
            "= i m writing an article for the school newspaper\n",
            "< i m the only one who old the day off\n",
            "\n",
            "> я второкурсник\n",
            "= i m a sophomore\n",
            "< she is a sophomore <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgZ9EshDq3-Z"
      },
      "source": [
        "### Визуализация внимания\n",
        "\n",
        "Полезным свойством механизма внимания является то, что его результаты легко интерпретируются. Поскольку он используется для взвешивания конкретных выходных данных кодера входной последовательности, мы можем представить, как смотрим, где сеть сосредоточена больше всего на каждом временном шаге.\n",
        "\n",
        "Вы можете просто запустить `plt.matshow(attentions)`, чтобы увидеть вывод внимания, отображаемый в виде матрицы. Для лучшего просмотра мы проделаем дополнительную работу по добавлению осей и меток:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "n564lIgiq3-Z",
        "outputId": "dd95e938-2f7b-45a7-a2e1-15801ecd1979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = это скучная книга\n",
            "output = i m eating this with this <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-b32e3d7a2ebd>:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-83-b32e3d7a2ebd>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = мы в безопасности\n",
            "output = we re safe in the safe <EOS>\n",
            "input = том в тюрьме\n",
            "output = tom s tom in jail <EOS>\n",
            "input = мы можем вам помочь\n",
            "output = we re able to help you <EOS>\n",
            "input = придется подождать\n",
            "output = you re going to have kept wait welcome <EOS>\n"
          ]
        }
      ],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "evaluateAndShowAttention('это скучная книга')\n",
        "evaluateAndShowAttention('мы в безопасности')\n",
        "evaluateAndShowAttention('том в тюрьме')\n",
        "evaluateAndShowAttention('мы можем вам помочь')\n",
        "evaluateAndShowAttention('придется подождать')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7JVuMctq3-Z"
      },
      "source": [
        "## Выводы\n",
        "\n",
        "Как видно из результатов, перевод оставляет желать лучшего. Также наличие того факта, что при переводе какого-либо слова, которое отсутствует во внутреннем словаре обучающего датасета, выбрасывается исключение, оставляет весьма негативные впечатлении о качестве такого переводчика. Однако, как минимальная интерпретация работы переводчика «изнутри», данный код дает хорошее понимание работы переводчиков в целом.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}